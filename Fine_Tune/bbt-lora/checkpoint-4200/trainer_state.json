{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.831012778943353,
  "eval_steps": 200,
  "global_step": 4200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02179777117789706,
      "grad_norm": 4.776612758636475,
      "learning_rate": 7.101449275362319e-05,
      "loss": 3.3417,
      "step": 50
    },
    {
      "epoch": 0.04359554235579412,
      "grad_norm": 1.7937378883361816,
      "learning_rate": 0.0001434782608695652,
      "loss": 2.4479,
      "step": 100
    },
    {
      "epoch": 0.06539331353369118,
      "grad_norm": 2.0897929668426514,
      "learning_rate": 0.00019999698197120989,
      "loss": 2.3562,
      "step": 150
    },
    {
      "epoch": 0.08719108471158823,
      "grad_norm": 2.9879188537597656,
      "learning_rate": 0.00019990720326787,
      "loss": 2.4232,
      "step": 200
    },
    {
      "epoch": 0.08719108471158823,
      "eval_loss": 2.359890937805176,
      "eval_runtime": 1021.149,
      "eval_samples_per_second": 4.64,
      "eval_steps_per_second": 4.64,
      "step": 200
    },
    {
      "epoch": 0.1089888558894853,
      "grad_norm": 1.8986247777938843,
      "learning_rate": 0.0001996928406813764,
      "loss": 2.3494,
      "step": 250
    },
    {
      "epoch": 0.13078662706738237,
      "grad_norm": 1.505151391029358,
      "learning_rate": 0.0001993541615210177,
      "loss": 2.3416,
      "step": 300
    },
    {
      "epoch": 0.15258439824527942,
      "grad_norm": 1.4892791509628296,
      "learning_rate": 0.00019889158811835315,
      "loss": 2.3824,
      "step": 350
    },
    {
      "epoch": 0.17438216942317647,
      "grad_norm": 1.6612385511398315,
      "learning_rate": 0.00019830569730056703,
      "loss": 2.3599,
      "step": 400
    },
    {
      "epoch": 0.17438216942317647,
      "eval_loss": 2.337796688079834,
      "eval_runtime": 1021.1426,
      "eval_samples_per_second": 4.64,
      "eval_steps_per_second": 4.64,
      "step": 400
    },
    {
      "epoch": 0.19617994060107355,
      "grad_norm": 2.047865867614746,
      "learning_rate": 0.00019759721967116734,
      "loss": 2.3215,
      "step": 450
    },
    {
      "epoch": 0.2179777117789706,
      "grad_norm": 1.1448427438735962,
      "learning_rate": 0.00019676703869892618,
      "loss": 2.3488,
      "step": 500
    },
    {
      "epoch": 0.23977548295686765,
      "grad_norm": 1.499666690826416,
      "learning_rate": 0.00019581618961619785,
      "loss": 2.3347,
      "step": 550
    },
    {
      "epoch": 0.26157325413476473,
      "grad_norm": 2.042525291442871,
      "learning_rate": 0.00019474585812798796,
      "loss": 2.3743,
      "step": 600
    },
    {
      "epoch": 0.26157325413476473,
      "eval_loss": 2.331408739089966,
      "eval_runtime": 1021.025,
      "eval_samples_per_second": 4.64,
      "eval_steps_per_second": 4.64,
      "step": 600
    },
    {
      "epoch": 0.2833710253126618,
      "grad_norm": 2.0722081661224365,
      "learning_rate": 0.00019355737893338434,
      "loss": 2.3246,
      "step": 650
    },
    {
      "epoch": 0.30516879649055884,
      "grad_norm": 1.8012583255767822,
      "learning_rate": 0.00019225223406119235,
      "loss": 2.3644,
      "step": 700
    },
    {
      "epoch": 0.3269665676684559,
      "grad_norm": 1.9809068441390991,
      "learning_rate": 0.0001908320510218511,
      "loss": 2.3716,
      "step": 750
    },
    {
      "epoch": 0.34876433884635294,
      "grad_norm": 1.7030367851257324,
      "learning_rate": 0.00018929860077793423,
      "loss": 2.3849,
      "step": 800
    },
    {
      "epoch": 0.34876433884635294,
      "eval_loss": 2.32869553565979,
      "eval_runtime": 1021.541,
      "eval_samples_per_second": 4.638,
      "eval_steps_per_second": 4.638,
      "step": 800
    },
    {
      "epoch": 0.37056211002425005,
      "grad_norm": 1.803011178970337,
      "learning_rate": 0.00018765379553576685,
      "loss": 2.3282,
      "step": 850
    },
    {
      "epoch": 0.3923598812021471,
      "grad_norm": 1.7830458879470825,
      "learning_rate": 0.0001858996863609118,
      "loss": 2.3483,
      "step": 900
    },
    {
      "epoch": 0.41415765238004415,
      "grad_norm": 1.5359160900115967,
      "learning_rate": 0.0001840384606204991,
      "loss": 2.3126,
      "step": 950
    },
    {
      "epoch": 0.4359554235579412,
      "grad_norm": 2.026750087738037,
      "learning_rate": 0.00018207243925558782,
      "loss": 2.3453,
      "step": 1000
    },
    {
      "epoch": 0.4359554235579412,
      "eval_loss": 2.3220698833465576,
      "eval_runtime": 1021.1999,
      "eval_samples_per_second": 4.64,
      "eval_steps_per_second": 4.64,
      "step": 1000
    },
    {
      "epoch": 0.45775319473583825,
      "grad_norm": 1.7589097023010254,
      "learning_rate": 0.000180004073886962,
      "loss": 2.3361,
      "step": 1050
    },
    {
      "epoch": 0.4795509659137353,
      "grad_norm": 1.7629965543746948,
      "learning_rate": 0.00017783594375796917,
      "loss": 2.3457,
      "step": 1100
    },
    {
      "epoch": 0.5013487370916324,
      "grad_norm": 1.7242627143859863,
      "learning_rate": 0.0001755707525182144,
      "loss": 2.3283,
      "step": 1150
    },
    {
      "epoch": 0.5231465082695295,
      "grad_norm": 1.442850947380066,
      "learning_rate": 0.0001732113248521199,
      "loss": 2.3071,
      "step": 1200
    },
    {
      "epoch": 0.5231465082695295,
      "eval_loss": 2.318727493286133,
      "eval_runtime": 1021.1612,
      "eval_samples_per_second": 4.64,
      "eval_steps_per_second": 4.64,
      "step": 1200
    },
    {
      "epoch": 0.5449442794474265,
      "grad_norm": 1.650095820426941,
      "learning_rate": 0.00017076060295655472,
      "loss": 2.3538,
      "step": 1250
    },
    {
      "epoch": 0.5667420506253236,
      "grad_norm": 1.5885941982269287,
      "learning_rate": 0.00016822164287192738,
      "loss": 2.3116,
      "step": 1300
    },
    {
      "epoch": 0.5885398218032206,
      "grad_norm": 1.8636503219604492,
      "learning_rate": 0.00016559761067131538,
      "loss": 2.2802,
      "step": 1350
    },
    {
      "epoch": 0.6103375929811177,
      "grad_norm": 1.6735657453536987,
      "learning_rate": 0.0001628917785123848,
      "loss": 2.2977,
      "step": 1400
    },
    {
      "epoch": 0.6103375929811177,
      "eval_loss": 2.3129968643188477,
      "eval_runtime": 1021.3663,
      "eval_samples_per_second": 4.639,
      "eval_steps_per_second": 4.639,
      "step": 1400
    },
    {
      "epoch": 0.6321353641590147,
      "grad_norm": 1.8507936000823975,
      "learning_rate": 0.00016010752055702282,
      "loss": 2.3068,
      "step": 1450
    },
    {
      "epoch": 0.6539331353369118,
      "grad_norm": 1.6331335306167603,
      "learning_rate": 0.00015724830876377133,
      "loss": 2.3728,
      "step": 1500
    },
    {
      "epoch": 0.6757309065148088,
      "grad_norm": 1.9221745729446411,
      "learning_rate": 0.00015431770855830847,
      "loss": 2.3359,
      "step": 1550
    },
    {
      "epoch": 0.6975286776927059,
      "grad_norm": 1.5463018417358398,
      "learning_rate": 0.00015131937438737708,
      "loss": 2.3403,
      "step": 1600
    },
    {
      "epoch": 0.6975286776927059,
      "eval_loss": 2.3097405433654785,
      "eval_runtime": 1021.1779,
      "eval_samples_per_second": 4.64,
      "eval_steps_per_second": 4.64,
      "step": 1600
    },
    {
      "epoch": 0.7193264488706029,
      "grad_norm": 1.2451943159103394,
      "learning_rate": 0.00014825704516170416,
      "loss": 2.3512,
      "step": 1650
    },
    {
      "epoch": 0.7411242200485001,
      "grad_norm": 1.7747939825057983,
      "learning_rate": 0.00014513453959359428,
      "loss": 2.3537,
      "step": 1700
    },
    {
      "epoch": 0.7629219912263971,
      "grad_norm": 1.6041706800460815,
      "learning_rate": 0.00014195575143501044,
      "loss": 2.3241,
      "step": 1750
    },
    {
      "epoch": 0.7847197624042942,
      "grad_norm": 1.3842251300811768,
      "learning_rate": 0.00013872464462208098,
      "loss": 2.3145,
      "step": 1800
    },
    {
      "epoch": 0.7847197624042942,
      "eval_loss": 2.306626796722412,
      "eval_runtime": 1021.509,
      "eval_samples_per_second": 4.638,
      "eval_steps_per_second": 4.638,
      "step": 1800
    },
    {
      "epoch": 0.8065175335821912,
      "grad_norm": 1.7218296527862549,
      "learning_rate": 0.0001354452483320872,
      "loss": 2.3041,
      "step": 1850
    },
    {
      "epoch": 0.8283153047600883,
      "grad_norm": 1.8321014642715454,
      "learning_rate": 0.00013212165195909526,
      "loss": 2.3077,
      "step": 1900
    },
    {
      "epoch": 0.8501130759379854,
      "grad_norm": 1.4529085159301758,
      "learning_rate": 0.00012875800001449806,
      "loss": 2.2656,
      "step": 1950
    },
    {
      "epoch": 0.8719108471158824,
      "grad_norm": 1.9734069108963013,
      "learning_rate": 0.00012535848695882626,
      "loss": 2.2718,
      "step": 2000
    },
    {
      "epoch": 0.8719108471158824,
      "eval_loss": 2.303356885910034,
      "eval_runtime": 1021.6997,
      "eval_samples_per_second": 4.637,
      "eval_steps_per_second": 4.637,
      "step": 2000
    },
    {
      "epoch": 0.8937086182937795,
      "grad_norm": 1.7186875343322754,
      "learning_rate": 0.00012192735197127272,
      "loss": 2.3553,
      "step": 2050
    },
    {
      "epoch": 0.9155063894716765,
      "grad_norm": 1.7219932079315186,
      "learning_rate": 0.00011846887366345292,
      "loss": 2.2988,
      "step": 2100
    },
    {
      "epoch": 0.9373041606495736,
      "grad_norm": 1.455385446548462,
      "learning_rate": 0.00011498736474399345,
      "loss": 2.2894,
      "step": 2150
    },
    {
      "epoch": 0.9591019318274706,
      "grad_norm": 1.7429581880569458,
      "learning_rate": 0.00011148716664060154,
      "loss": 2.3021,
      "step": 2200
    },
    {
      "epoch": 0.9591019318274706,
      "eval_loss": 2.300102472305298,
      "eval_runtime": 1021.4138,
      "eval_samples_per_second": 4.639,
      "eval_steps_per_second": 4.639,
      "step": 2200
    },
    {
      "epoch": 0.9808997030053677,
      "grad_norm": 1.7827732563018799,
      "learning_rate": 0.00010797264408632213,
      "loss": 2.2784,
      "step": 2250
    },
    {
      "epoch": 1.0026974741832648,
      "grad_norm": 1.5784428119659424,
      "learning_rate": 0.0001044481796767331,
      "loss": 2.2719,
      "step": 2300
    },
    {
      "epoch": 1.0244952453611618,
      "grad_norm": 2.178501844406128,
      "learning_rate": 0.00010091816840486624,
      "loss": 2.2717,
      "step": 2350
    },
    {
      "epoch": 1.046293016539059,
      "grad_norm": 1.6097750663757324,
      "learning_rate": 9.745761804185345e-05,
      "loss": 2.2107,
      "step": 2400
    },
    {
      "epoch": 1.046293016539059,
      "eval_loss": 2.2983689308166504,
      "eval_runtime": 1021.8202,
      "eval_samples_per_second": 4.637,
      "eval_steps_per_second": 4.637,
      "step": 2400
    },
    {
      "epoch": 1.0680907877169559,
      "grad_norm": 1.459351658821106,
      "learning_rate": 9.392961189983258e-05,
      "loss": 2.2748,
      "step": 2450
    },
    {
      "epoch": 1.089888558894853,
      "grad_norm": 1.9304721355438232,
      "learning_rate": 9.040917550750975e-05,
      "loss": 2.2973,
      "step": 2500
    },
    {
      "epoch": 1.11168633007275,
      "grad_norm": 1.8979337215423584,
      "learning_rate": 8.690069883499528e-05,
      "loss": 2.2741,
      "step": 2550
    },
    {
      "epoch": 1.1334841012506471,
      "grad_norm": 1.6925314664840698,
      "learning_rate": 8.34085569386767e-05,
      "loss": 2.2413,
      "step": 2600
    },
    {
      "epoch": 1.1334841012506471,
      "eval_loss": 2.2989230155944824,
      "eval_runtime": 1021.8363,
      "eval_samples_per_second": 4.637,
      "eval_steps_per_second": 4.637,
      "step": 2600
    },
    {
      "epoch": 1.155281872428544,
      "grad_norm": 1.5975135564804077,
      "learning_rate": 7.993710450554089e-05,
      "loss": 2.2533,
      "step": 2650
    },
    {
      "epoch": 1.1770796436064412,
      "grad_norm": 1.7428576946258545,
      "learning_rate": 7.64906704228968e-05,
      "loss": 2.2675,
      "step": 2700
    },
    {
      "epoch": 1.1988774147843384,
      "grad_norm": 1.8306090831756592,
      "learning_rate": 7.30735523802704e-05,
      "loss": 2.2542,
      "step": 2750
    },
    {
      "epoch": 1.2206751859622353,
      "grad_norm": 1.8819657564163208,
      "learning_rate": 6.969001151020288e-05,
      "loss": 2.2571,
      "step": 2800
    },
    {
      "epoch": 1.2206751859622353,
      "eval_loss": 2.2968554496765137,
      "eval_runtime": 1021.4288,
      "eval_samples_per_second": 4.639,
      "eval_steps_per_second": 4.639,
      "step": 2800
    },
    {
      "epoch": 1.2424729571401325,
      "grad_norm": 2.224473714828491,
      "learning_rate": 6.634426707463545e-05,
      "loss": 2.2822,
      "step": 2850
    },
    {
      "epoch": 1.2642707283180294,
      "grad_norm": 1.4729259014129639,
      "learning_rate": 6.304049120350664e-05,
      "loss": 2.2808,
      "step": 2900
    },
    {
      "epoch": 1.2860684994959266,
      "grad_norm": 1.5593774318695068,
      "learning_rate": 5.978280369212276e-05,
      "loss": 2.2873,
      "step": 2950
    },
    {
      "epoch": 1.3078662706738235,
      "grad_norm": 2.262786388397217,
      "learning_rate": 5.657526686378975e-05,
      "loss": 2.2918,
      "step": 3000
    },
    {
      "epoch": 1.3078662706738235,
      "eval_loss": 2.294717788696289,
      "eval_runtime": 1021.9746,
      "eval_samples_per_second": 4.636,
      "eval_steps_per_second": 4.636,
      "step": 3000
    },
    {
      "epoch": 1.3296640418517207,
      "grad_norm": 2.4067189693450928,
      "learning_rate": 5.342188050411235e-05,
      "loss": 2.2025,
      "step": 3050
    },
    {
      "epoch": 1.3514618130296177,
      "grad_norm": 2.2156546115875244,
      "learning_rate": 5.03265768732772e-05,
      "loss": 2.2744,
      "step": 3100
    },
    {
      "epoch": 1.3732595842075148,
      "grad_norm": 1.4792466163635254,
      "learning_rate": 4.7293215802540215e-05,
      "loss": 2.2884,
      "step": 3150
    },
    {
      "epoch": 1.3950573553854118,
      "grad_norm": 1.9639877080917358,
      "learning_rate": 4.432557988103253e-05,
      "loss": 2.2873,
      "step": 3200
    },
    {
      "epoch": 1.3950573553854118,
      "eval_loss": 2.2932679653167725,
      "eval_runtime": 1021.6568,
      "eval_samples_per_second": 4.638,
      "eval_steps_per_second": 4.638,
      "step": 3200
    },
    {
      "epoch": 1.416855126563309,
      "grad_norm": 2.227339029312134,
      "learning_rate": 4.14273697388869e-05,
      "loss": 2.2414,
      "step": 3250
    },
    {
      "epoch": 1.438652897741206,
      "grad_norm": 1.775071144104004,
      "learning_rate": 3.8602199432566585e-05,
      "loss": 2.2936,
      "step": 3300
    },
    {
      "epoch": 1.460450668919103,
      "grad_norm": 1.7009235620498657,
      "learning_rate": 3.5853591938151656e-05,
      "loss": 2.2486,
      "step": 3350
    },
    {
      "epoch": 1.482248440097,
      "grad_norm": 1.770833969116211,
      "learning_rate": 3.318497475820164e-05,
      "loss": 2.2625,
      "step": 3400
    },
    {
      "epoch": 1.482248440097,
      "eval_loss": 2.2935924530029297,
      "eval_runtime": 1021.7463,
      "eval_samples_per_second": 4.637,
      "eval_steps_per_second": 4.637,
      "step": 3400
    },
    {
      "epoch": 1.5040462112748971,
      "grad_norm": 2.048269748687744,
      "learning_rate": 3.059967564767363e-05,
      "loss": 2.2095,
      "step": 3450
    },
    {
      "epoch": 1.5258439824527943,
      "grad_norm": 1.554795265197754,
      "learning_rate": 2.81009184642253e-05,
      "loss": 2.2633,
      "step": 3500
    },
    {
      "epoch": 1.5476417536306912,
      "grad_norm": 1.8838005065917969,
      "learning_rate": 2.5691819148077035e-05,
      "loss": 2.2279,
      "step": 3550
    },
    {
      "epoch": 1.5694395248085882,
      "grad_norm": 2.005394220352173,
      "learning_rate": 2.337538183644702e-05,
      "loss": 2.2752,
      "step": 3600
    },
    {
      "epoch": 1.5694395248085882,
      "eval_loss": 2.2917163372039795,
      "eval_runtime": 1021.6746,
      "eval_samples_per_second": 4.637,
      "eval_steps_per_second": 4.637,
      "step": 3600
    },
    {
      "epoch": 1.5912372959864853,
      "grad_norm": 1.8346540927886963,
      "learning_rate": 2.115449511740436e-05,
      "loss": 2.2687,
      "step": 3650
    },
    {
      "epoch": 1.6130350671643825,
      "grad_norm": 1.4979454278945923,
      "learning_rate": 1.903192842781094e-05,
      "loss": 2.2034,
      "step": 3700
    },
    {
      "epoch": 1.6348328383422794,
      "grad_norm": 1.648526906967163,
      "learning_rate": 1.7010328599844917e-05,
      "loss": 2.2606,
      "step": 3750
    },
    {
      "epoch": 1.6566306095201766,
      "grad_norm": 1.6077349185943604,
      "learning_rate": 1.5092216560411631e-05,
      "loss": 2.3035,
      "step": 3800
    },
    {
      "epoch": 1.6566306095201766,
      "eval_loss": 2.2916855812072754,
      "eval_runtime": 1021.7944,
      "eval_samples_per_second": 4.637,
      "eval_steps_per_second": 4.637,
      "step": 3800
    },
    {
      "epoch": 1.6784283806980738,
      "grad_norm": 1.4119915962219238,
      "learning_rate": 1.3279984187557682e-05,
      "loss": 2.2142,
      "step": 3850
    },
    {
      "epoch": 1.7002261518759707,
      "grad_norm": 1.9005632400512695,
      "learning_rate": 1.1575891327808663e-05,
      "loss": 2.2886,
      "step": 3900
    },
    {
      "epoch": 1.7220239230538676,
      "grad_norm": 1.8142197132110596,
      "learning_rate": 9.982062978149587e-06,
      "loss": 2.2561,
      "step": 3950
    },
    {
      "epoch": 1.7438216942317648,
      "grad_norm": 1.837599277496338,
      "learning_rate": 8.500486636162031e-06,
      "loss": 2.2567,
      "step": 4000
    },
    {
      "epoch": 1.7438216942317648,
      "eval_loss": 2.2911791801452637,
      "eval_runtime": 1021.7959,
      "eval_samples_per_second": 4.637,
      "eval_steps_per_second": 4.637,
      "step": 4000
    },
    {
      "epoch": 1.765619465409662,
      "grad_norm": 1.7413142919540405,
      "learning_rate": 7.133009821622727e-06,
      "loss": 2.2418,
      "step": 4050
    },
    {
      "epoch": 1.787417236587559,
      "grad_norm": 1.7683160305023193,
      "learning_rate": 5.8813377726537275e-06,
      "loss": 2.1791,
      "step": 4100
    },
    {
      "epoch": 1.8092150077654559,
      "grad_norm": 1.7580169439315796,
      "learning_rate": 4.747031319297235e-06,
      "loss": 2.2453,
      "step": 4150
    },
    {
      "epoch": 1.831012778943353,
      "grad_norm": 1.755398154258728,
      "learning_rate": 3.7315049371668407e-06,
      "loss": 2.2342,
      "step": 4200
    },
    {
      "epoch": 1.831012778943353,
      "eval_loss": 2.2911553382873535,
      "eval_runtime": 1021.8404,
      "eval_samples_per_second": 4.637,
      "eval_steps_per_second": 4.637,
      "step": 4200
    }
  ],
  "logging_steps": 50,
  "max_steps": 4586,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 200,
  "total_flos": 5.93571770813399e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
